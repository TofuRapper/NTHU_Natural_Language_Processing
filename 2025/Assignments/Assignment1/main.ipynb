{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Part I: Data Pre-processing"
      ],
      "metadata": {
        "id": "p6yklm2xWn9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "YycoIJomXwqH"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the Google Analogy dataset\n",
        "!wget http://download.tensorflow.org/data/questions-words.txt"
      ],
      "metadata": {
        "id": "KKAXuhZIUxD8",
        "outputId": "84ec1ad1-867e-4971-c4a4-7f959391e04e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-18 15:58:16--  http://download.tensorflow.org/data/questions-words.txt\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.139.207, 108.177.12.207, 173.194.210.207, ...\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.139.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 603955 (590K) [text/plain]\n",
            "Saving to: ‘questions-words.txt.7’\n",
            "\n",
            "\rquestions-words.txt   0%[                    ]       0  --.-KB/s               \rquestions-words.txt 100%[===================>] 589.80K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-09-18 15:58:16 (18.8 MB/s) - ‘questions-words.txt.7’ saved [603955/603955]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the dataset\n",
        "file_name = \"questions-words\"\n",
        "with open(f\"{file_name}.txt\", \"r\") as f:\n",
        "    data = f.read().splitlines()"
      ],
      "metadata": {
        "id": "xue5pVFLVNQQ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check data from the first 10 entries\n",
        "for entry in data[:10]:\n",
        "    print(entry)"
      ],
      "metadata": {
        "id": "h7dOdJOsZzAF",
        "outputId": "88ccc991-7a74-43eb-ef92-d16f61578cf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ": capital-common-countries\n",
            "Athens Greece Baghdad Iraq\n",
            "Athens Greece Bangkok Thailand\n",
            "Athens Greece Beijing China\n",
            "Athens Greece Berlin Germany\n",
            "Athens Greece Bern Switzerland\n",
            "Athens Greece Cairo Egypt\n",
            "Athens Greece Canberra Australia\n",
            "Athens Greece Hanoi Vietnam\n",
            "Athens Greece Havana Cuba\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO1: Write your code here for processing data to pd.DataFrame\n",
        "# Please note that the first five mentions of \": \" indicate `semantic`,\n",
        "# and the remaining nine belong to the `syntatic` category.\n",
        "questions = []\n",
        "categories = []\n",
        "sub_categories = []\n",
        "\n",
        "current_subcat = None      # 目前的小類別（由以 \": \" 開頭的行決定）\n",
        "subcat_count = -1          # 計算遇到幾次 \": \"（用來決定 semantic/syntactic）\n",
        "\n",
        "for line in data:\n",
        "    line = line.strip()\n",
        "    if not line:\n",
        "        continue\n",
        "\n",
        "    # 小類別標頭（例如 \": capital-common-countries\"）\n",
        "    if line.startswith(\":\"):\n",
        "        # 去掉前綴 \":\" 或 \": \"\n",
        "        current_subcat = line.lstrip(\":\").strip()\n",
        "        subcat_count += 1\n",
        "        continue\n",
        "\n",
        "    # 題目行：四個字 (a b c d)\n",
        "    tokens = line.split()\n",
        "    if len(tokens) != 4:\n",
        "        # 非標準行就略過\n",
        "        continue\n",
        "\n",
        "    # 題目字串（後面 Part II 會再拆回 a,b,c,d 使用）\n",
        "    questions.append(\" \".join(tokens))\n",
        "\n",
        "    # 前 5 個小類別屬於 semantic，其餘 9 個屬於 syntactic\n",
        "    cat = \"semantic\" if subcat_count < 5 else \"syntactic\"\n",
        "    categories.append(cat)\n",
        "\n",
        "    # 紀錄小類別名稱\n",
        "    sub_categories.append(current_subcat)\n",
        "\n"
      ],
      "metadata": {
        "id": "wmYQ0IWZZxf3"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the dataframe\n",
        "df = pd.DataFrame(\n",
        "    {\n",
        "        \"Question\": questions,\n",
        "        \"Category\": categories,\n",
        "        \"SubCategory\": sub_categories,\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "_bKA05rVZb_i"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "UN2FBcicZmpV",
        "outputId": "c950fa0e-d0ca-4b65-81c6-710ea1de9fd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         Question  Category               SubCategory\n",
              "0      Athens Greece Baghdad Iraq  semantic  capital-common-countries\n",
              "1  Athens Greece Bangkok Thailand  semantic  capital-common-countries\n",
              "2     Athens Greece Beijing China  semantic  capital-common-countries\n",
              "3    Athens Greece Berlin Germany  semantic  capital-common-countries\n",
              "4  Athens Greece Bern Switzerland  semantic  capital-common-countries"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2fc37bed-15e4-4c08-9593-bf537affc66b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Category</th>\n",
              "      <th>SubCategory</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Athens Greece Baghdad Iraq</td>\n",
              "      <td>semantic</td>\n",
              "      <td>capital-common-countries</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Athens Greece Bangkok Thailand</td>\n",
              "      <td>semantic</td>\n",
              "      <td>capital-common-countries</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Athens Greece Beijing China</td>\n",
              "      <td>semantic</td>\n",
              "      <td>capital-common-countries</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Athens Greece Berlin Germany</td>\n",
              "      <td>semantic</td>\n",
              "      <td>capital-common-countries</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Athens Greece Bern Switzerland</td>\n",
              "      <td>semantic</td>\n",
              "      <td>capital-common-countries</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2fc37bed-15e4-4c08-9593-bf537affc66b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2fc37bed-15e4-4c08-9593-bf537affc66b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2fc37bed-15e4-4c08-9593-bf537affc66b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0bdcfd15-ea01-422c-a633-352abb18905a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0bdcfd15-ea01-422c-a633-352abb18905a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0bdcfd15-ea01-422c-a633-352abb18905a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 19544,\n  \"fields\": [\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19373,\n        \"samples\": [\n          \"Windhoek Namibia Accra Ghana\",\n          \"Nashville Tennessee Plano Texas\",\n          \"Vilnius Lithuania Zagreb Croatia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"syntactic\",\n          \"semantic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SubCategory\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"gram5-present-participle\",\n          \"gram7-past-tense\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(f\"{file_name}.csv\", index=False)"
      ],
      "metadata": {
        "id": "nMGvoDeiZhbp"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part II: Use pre-trained word embeddings\n",
        "- After finish Part I, you can run Part II code blocks only."
      ],
      "metadata": {
        "id": "Zi2SNNuHWiZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim.downloader\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE"
      ],
      "metadata": {
        "id": "yB4rpJymXiSN",
        "outputId": "a2f36af6-cc15-48aa-ae8d-8a0e9e6e6427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'gensim'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-996662960.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"questions-words.csv\")"
      ],
      "metadata": {
        "id": "-pGLoyKSHXuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"glove-wiki-gigaword-100\"\n",
        "# You can try other models.\n",
        "# https://radimrehurek.com/gensim/models/word2vec.html#pretrained-models\n",
        "\n",
        "# Load the pre-trained model (using GloVe vectors here)\n",
        "model = gensim.downloader.load(MODEL_NAME)\n",
        "print(\"The Gensim model loaded successfully!\")"
      ],
      "metadata": {
        "id": "YWa_1hF3aZHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do predictions and preserve the gold answers (word_D)\n",
        "preds = []\n",
        "golds = []\n",
        "\n",
        "for analogy in tqdm(data[\"Question\"]):\n",
        "      # TODO2: Write your code here to use pre-trained word embeddings for getting predictions of the analogy task.\n",
        "      # You should also preserve the gold answers during iterations for evaluations later.\n",
        "      \"\"\" Hints\n",
        "      # Unpack the analogy (e.g., \"man\", \"woman\", \"king\", \"queen\")\n",
        "      # Perform vector arithmetic: word_b + word_c - word_a should be close to word_d\n",
        "      # Source: https://github.com/piskvorky/gensim/blob/develop/gensim/models/keyedvectors.py#L776\n",
        "      # Mikolov et al., 2013: big - biggest and small - smallest\n",
        "      # Mikolov et al., 2013: X = vector(”biggest”) − vector(”big”) + vector(”small”).\n",
        "      \"\"\""
      ],
      "metadata": {
        "id": "YTsqJcP1WSTH",
        "outputId": "7f54c37c-f1a0-4687-cbdb-2e4caea55991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tqdm' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3249981994.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0manalogy\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Question\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m       \u001b[0;31m# TODO2: Write your code here to use pre-trained word embeddings for getting predictions of the analogy task.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0;31m# You should also preserve the gold answers during iterations for evaluations later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform evaluations. You do not need to modify this block!!\n",
        "\n",
        "def calculate_accuracy(gold: np.ndarray, pred: np.ndarray) -> float:\n",
        "    return np.mean(gold == pred)\n",
        "\n",
        "golds_np, preds_np = np.array(golds), np.array(preds)\n",
        "data = pd.read_csv(\"questions-words.csv\")\n",
        "\n",
        "# Evaluation: categories\n",
        "for category in data[\"Category\"].unique():\n",
        "    mask = data[\"Category\"] == category\n",
        "    golds_cat, preds_cat = golds_np[mask], preds_np[mask]\n",
        "    acc_cat = calculate_accuracy(golds_cat, preds_cat)\n",
        "    print(f\"Category: {category}, Accuracy: {acc_cat * 100}%\")\n",
        "\n",
        "# Evaluation: sub-categories\n",
        "for sub_category in data[\"SubCategory\"].unique():\n",
        "    mask = data[\"SubCategory\"] == sub_category\n",
        "    golds_subcat, preds_subcat = golds_np[mask], preds_np[mask]\n",
        "    acc_subcat = calculate_accuracy(golds_subcat, preds_subcat)\n",
        "    print(f\"Sub-Category{sub_category}, Accuracy: {acc_subcat * 100}%\")"
      ],
      "metadata": {
        "id": "xG7vcPXAW6uT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect words from Google Analogy dataset\n",
        "SUB_CATEGORY = \": family\"\n",
        "\n",
        "# TODO3: Plot t-SNE for the words in the SUB_CATEGORY `: family`\n",
        "\n",
        "\n",
        "plt.title(\"Word Relationships from Google Analogy Task\")\n",
        "plt.show()\n",
        "plt.savefig(\"word_relationships.png\", bbox_inches=\"tight\")"
      ],
      "metadata": {
        "id": "7_z6CybBXKZu",
        "outputId": "8e53305c-d739-466e-e3c4-461da7b55328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-173991832.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Word Relationships from Google Analogy Task\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word_relationships.png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_inches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tight\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part III: Train your own word embeddings"
      ],
      "metadata": {
        "id": "DKRPJxgKXH4j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get the latest English Wikipedia articles and do sampling.\n",
        "- Usually, we start from Wikipedia dump (https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2). However, the downloading step will take very long. Also, the cleaning step for the Wikipedia corpus ([`gensim.corpora.wikicorpus.WikiCorpus`](https://radimrehurek.com/gensim/corpora/wikicorpus.html#gensim.corpora.wikicorpus.WikiCorpus)) will take much time. Therefore, we provide cleaned files for you."
      ],
      "metadata": {
        "id": "VC_0fE1UzL8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the split Wikipedia files\n",
        "# Each file contain 562365 lines (articles).\n",
        "!gdown --id 1jiu9E1NalT2Y8EIuWNa1xf2Tw1f1XuGd -O wiki_texts_part_0.txt.gz\n",
        "!gdown --id 1ABblLRd9HXdXvaNv8H9fFq984bhnowoG -O wiki_texts_part_1.txt.gz\n",
        "!gdown --id 1z2VFNhpPvCejTP5zyejzKj5YjI_Bn42M -O wiki_texts_part_2.txt.gz\n",
        "!gdown --id 1VKjded9BxADRhIoCzXy_W8uzVOTWIf0g -O wiki_texts_part_3.txt.gz\n",
        "!gdown --id 16mBeG26m9LzHXdPe8UrijUIc6sHxhknz -O wiki_texts_part_4.txt.gz"
      ],
      "metadata": {
        "id": "FkubArwCCYxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the split Wikipedia files\n",
        "# Each file contain 562365 lines (articles), except the last file.\n",
        "!gdown --id 17JFvxOH-kc-VmvGkhG7p3iSZSpsWdgJI -O wiki_texts_part_5.txt.gz\n",
        "!gdown --id 19IvB2vOJRGlrYulnTXlZECR8zT5v550P -O wiki_texts_part_6.txt.gz\n",
        "!gdown --id 1sjwO8A2SDOKruv6-8NEq7pEIuQ50ygVV -O wiki_texts_part_7.txt.gz\n",
        "!gdown --id 1s7xKWJmyk98Jbq6Fi1scrHy7fr_ellUX -O wiki_texts_part_8.txt.gz\n",
        "!gdown --id 17eQXcrvY1cfpKelLbP2BhQKrljnFNykr -O wiki_texts_part_9.txt.gz\n",
        "!gdown --id 1J5TAN6bNBiSgTIYiPwzmABvGhAF58h62 -O wiki_texts_part_10.txt.gz"
      ],
      "metadata": {
        "id": "8S3ibNT3C8Xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the downloaded wiki_texts_parts files.\n",
        "!gunzip -k wiki_texts_part_*.gz"
      ],
      "metadata": {
        "id": "DUg_c79BC7OL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the extracted wiki_texts_parts files.\n",
        "!cat wiki_texts_part_*.txt > wiki_texts_combined.txt"
      ],
      "metadata": {
        "id": "7duk2RbYDB02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first ten lines of the combined file\n",
        "!head -n 10 wiki_texts_combined.txt"
      ],
      "metadata": {
        "id": "givLH7NrDs6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please note that we used the default parameters of [`gensim.corpora.wikicorpus.WikiCorpus`](https://radimrehurek.com/gensim/corpora/wikicorpus.html#gensim.corpora.wikicorpus.WikiCorpus) for cleaning the Wiki raw file. Thus, words with one character were discarded."
      ],
      "metadata": {
        "id": "Hfwx92QCEhrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now you need to do sampling because the corpus is too big.\n",
        "# You can further perform analysis with a greater sampling ratio.\n",
        "\n",
        "import random\n",
        "\n",
        "wiki_txt_path = \"wiki_texts_combined.txt\"\n",
        "# wiki_texts_combined.txt is a text file separated by linebreaks (\\n).\n",
        "# Each row in wiki_texts_combined.txt indicates a Wikipedia article.\n",
        "\n",
        "with open(wiki_txt_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as output_file:\n",
        "    # TODO4: Sample `20%` Wikipedia articles\n",
        "    # Write your code here"
      ],
      "metadata": {
        "id": "vUAzButoP03w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO5: Train your own word embeddings with the sampled articles\n",
        "# https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec\n",
        "# Hint: You should perform some pre-processing before training."
      ],
      "metadata": {
        "id": "G7q1Xzunxkdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"questions-words.csv\")"
      ],
      "metadata": {
        "id": "qWiQF70izxP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do predictions and preserve the gold answers (word_D)\n",
        "preds = []\n",
        "golds = []\n",
        "\n",
        "for analogy in tqdm(data[\"Question\"]):\n",
        "      # TODO6: Write your code here to use your trained word embeddings for getting predictions of the analogy task.\n",
        "      # You should also preserve the gold answers during iterations for evaluations later.\n",
        "      \"\"\" Hints\n",
        "      # Unpack the analogy (e.g., \"man\", \"woman\", \"king\", \"queen\")\n",
        "      # Perform vector arithmetic: word_b + word_c - word_a should be close to word_d\n",
        "      # Source: https://github.com/piskvorky/gensim/blob/develop/gensim/models/keyedvectors.py#L776\n",
        "      # Mikolov et al., 2013: big - biggest and small - smallest\n",
        "      # Mikolov et al., 2013: X = vector(”biggest”) − vector(”big”) + vector(”small”).\n",
        "      \"\"\""
      ],
      "metadata": {
        "id": "q6xpqgdIy5x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect words from Google Analogy dataset\n",
        "SUB_CATEGORY = \": family\"\n",
        "\n",
        "# TODO7: Plot t-SNE for the words in the SUB_CATEGORY `: family`\n",
        "\n",
        "\n",
        "plt.title(\"Word Relationships from Google Analogy Task\")\n",
        "plt.show()\n",
        "plt.savefig(\"word_relationships.png\", bbox_inches=\"tight\")"
      ],
      "metadata": {
        "id": "AjZ14dQL0mhf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}